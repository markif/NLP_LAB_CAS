{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf3db8c0-e971-4d5c-a555-93a3268955be",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"400\" src=\"https://drive.google.com/thumbnail?id=1rPeHEqFWHJcauZlU82a4hXM10TUjmHxM&sz=s4000\" alt=\"FHNW Logo\">\n",
    "\n",
    "\n",
    "# Build an Agent\n",
    "\n",
    "by Fabian Märki\n",
    "\n",
    "## Summary\n",
    "The aim of this notebook is to showcase how to build an agent - i.e. how to combine a LLM with tools to create a system that can reason about tasks, decide which tools to use and iteratively work towards solutions.\n",
    "\n",
    "In its most fundamental form, an agent consists of three core components:\n",
    "- **Model:** The LLM powering the agent’s reasoning and decision-making\n",
    "- **Tools:** External functions or APIs the agent can use to take action\n",
    "- **Instructions:** Explicit guidelines and guardrails defining how the agent behaves\n",
    "\n",
    "Tools extend your agent's capabilities by using APIs from underlying applications or systems. Broadly speaking, agents need three types of tools:\n",
    "- **Data:** Enable agents to retrieve context and information necessary for executing the workflow (e.g. query databases, read PDF documents, or search the web).\n",
    "- **Action:** Enable agents to interact with systems to take actions such as adding new information to databases, updating records, or sending messages (e.g. send emails and texts, hand-off a customer service ticket to a human).\n",
    "- **Orchestration:** Agents themselves can serve as tools for other agents (research agent (web), writing agent (summarize), refund agent, translation agent)\n",
    "\n",
    "High-quality instructions are essential for any LLM-powered app, but especially critical for agents. Clear instructions reduce ambiguity and improve agent decision-making, resulting in smoother workflow execution and fewer errors.\n",
    "- **Prompt agents to break down tasks:** Providing smaller, clearer steps from dense resources helps minimize ambiguity and helps the model better follow instructions.\n",
    "- **Define clear actions:** Make sure every step in your routine corresponds to a specific action or output. For example, a step might instruct the agent to ask the user for their order number or to call an API to retrieve account details. Being explicit about the action (and even the wording of a user-facing message) leaves less room for errors in interpretation.\n",
    "- **Capture (anticipate) edge cases:** Real-world interactions often create decision points such as how to proceed when a user provides incomplete information or asks an unexpected question. A robust routine anticipates common variations and includes instructions on how to handle them with conditional steps or branches such as an alternative step if a required piece of info is missing.\n",
    "\n",
    "\n",
    "## Links\n",
    "- [LangChain Agents](https://docs.langchain.com/oss/python/langchain/agents)\n",
    "- [LangChain Tools](https://docs.langchain.com/oss/python/langchain/tools): Components that agents call to perform actions\n",
    "- [A Practical Guide to Building Agents](https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf) by OpenAI\n",
    "\n",
    "## Next steps:\n",
    "\n",
    "- Explore predefined [Tools](https://docs.langchain.com/oss/javascript/integrations/tools)\n",
    "- Learn about the [Model Context Protocol](https://de.wikipedia.org/wiki/Model_Context_Protocol) (MCP)\n",
    "- Investigate how to build a [custom MCP server](https://docs.langchain.com/oss/python/langchain/mcp#custom-mcp-servers) where you can provide your own tools\n",
    "\n",
    "This notebook contains assigments: <font color='red'>Questions are written in red.</font>\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/markif/NLP_LAB_CAS/blob/master/Build_an_Agent.ipynb\">\n",
    "  <img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9645f6b0-8ef7-47cf-bd8d-477441f2e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLLAMA_HOST='https://XYZ.trycloudflare.com'\n",
    "OLLAMA_HOST='http://localhost:11434'\n",
    "OPENAI_BASE_URL=OLLAMA_HOST+\"/v1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b56aed43-95f1-4f8d-b6d5-bc1a7d562dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install 'fhnw-nlp-utils>=0.11.0,<0.12.0'\n",
    "\n",
    "from fhnw.nlp.utils.storage import download\n",
    "from fhnw.nlp.utils.transformers import get_compute_device\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5068c038-dcd2-47c3-a170-a94167088d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# ensure we use latest langchain (needed for google colab)\n",
    "!pip uninstall -y langchain\n",
    "!pip uninstall -y langchain-classic\n",
    "!pip uninstall -y langchain-community\n",
    "!pip uninstall -y langchain_core\n",
    "!pip uninstall -y langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0166776c-b32c-4f53-a2d5-f485776c37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install pdfplumber\n",
    "\n",
    "!pip install langchain\n",
    "!pip install langchain-classic\n",
    "!pip install langchain-community\n",
    "!pip install langchain_core\n",
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48c426-a5c2-447f-af22-20df783073ff",
   "metadata": {},
   "source": [
    "Enable verbose/debug to see detailed output (see [here](https://python.langchain.com/docs/how_to/debugging/#set_debug-and-set_verbose))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8c044cb-bc2a-46d3-8b7d-c39b83fe6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.globals import set_verbose\n",
    "from langchain_classic.globals import set_debug\n",
    "\n",
    "set_verbose(False)\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c282cfcf-6148-4a5a-a361-e7d82214c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder = \"data/pdfs\"\n",
    "\n",
    "invoice_01 = pdf_folder + \"/file_01.pdf\"\n",
    "invoice_02 = pdf_folder + \"/file_02.pdf\"\n",
    "\n",
    "download(\"https://drive.switch.ch/index.php/s/TgZD1UtpTtSyP4h/download\", invoice_01)\n",
    "download(\"https://drive.switch.ch/index.php/s/9Hx5HclCxbS7Lzz/download\", invoice_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f035e-88e7-4d35-8180-4f658b393e1a",
   "metadata": {},
   "source": [
    "<font color='red'>**TASK: Provide code that can load PDF content (e.g. use [PDFPlumber](https://docs.langchain.com/oss/python/integrations/document_loaders/pdfplumber) or see [here](https://docs.langchain.com/oss/python/integrations/document_loaders#pdfs) for alternatives provided by LangChain that works out of the box).**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "742ba3db-e1fe-4dec-8990-b674263087a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Smith\n",
      "4490 Oak Drive\n",
      "Albarry, NY 12210\n",
      "Albarry 15.11.2025\n",
      "Jessie Home\n",
      "4312 Wood Road\n",
      "New York, NY 10031\n",
      "Invoice\n",
      "Date Description QTY Unit Price Amount\n",
      "14.11.2025 Front and rear brake cables 1 $15.00 $15.00\n",
      "14.11.2025 New set of pedal arms 2 $25.00 $50.00\n",
      "14.11.2025 Labor 3 $60.00 $180.00\n",
      "Tax 8.10% $19.85\n",
      "Total Payment due within 30 Days (15.12.2025) $264.85\n",
      "Thank you\n",
      "John Smith\n",
      "Seite 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from langchain_community.document_loaders import ...\n",
    "\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "loader = PDFPlumberLoader(invoice_01)\n",
    "documents = loader.load()\n",
    "\n",
    "print(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bdc4bc3-6f21-4786-be96-906505cdb5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='John Smith\n",
      "4490 Oak Drive\n",
      "Albarry, NY 12210\n",
      "Albarry 15.11.2025\n",
      "Jessie Home\n",
      "4312 Wood Road\n",
      "New York, NY 10031\n",
      "Invoice\n",
      "Date Description QTY Unit Price Amount\n",
      "14.11.2025 Front and rear brake cables 1 $15.00 $15.00\n",
      "14.11.2025 New set of pedal arms 2 $25.00 $50.00\n",
      "14.11.2025 Labor 3 $60.00 $180.00\n",
      "Tax 8.10% $19.85\n",
      "Total Payment due within 30 Days (15.12.2025) $264.85\n",
      "Thank you\n",
      "John Smith\n",
      "Seite 1\n",
      "' metadata={'source': 'data/pdfs/file_01.pdf', 'file_path': 'data/pdfs/file_01.pdf', 'page': 0, 'total_pages': 1, 'Creator': 'Calc', 'Producer': 'LibreOffice 24.2', 'CreationDate': \"D:20251115142215+01'00'\"}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8740c-a6da-41de-b791-c7328a5d49c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb1432eb-861f-489b-aa83-1ebe42d5f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0069cd77-dae5-4d56-8aab-b9fc66e1db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TEXT = \"qwen3:4b\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=MODEL_TEXT,\n",
    "    api_key=\"ollama\",\n",
    "    base_url=OPENAI_BASE_URL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018152d6-db52-448a-afc4-917c1f048a93",
   "metadata": {},
   "source": [
    "<font color='red'>**TASK: Come up with a prompt that asks the LLM to answer a question about a PDF.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eab4b24-8a5f-46db-9d71-ebeb4cd1ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"...\"\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"...\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3047fff0-0733-44c4-87b0-cdfb3981ada2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PDF is an invoice for vehicle repairs, listing parts (front and rear brake cables, pedal arms) and labor services with a total payment due of $264.85 by December 15, 2025.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"question\": \"What is the following PDF about?\",\n",
    "        \"pdf\": documents[0].page_content,\n",
    "        \"instructions\": \"Answer the question with one sentence only. Do not make things up and say so if you cannot answer the question.\",\n",
    "    }\n",
    ")\n",
    "    \n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97cbe83e-5e50-42fd-91b5-fd883f161764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/pdfs/file_01.pdf'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63041590-4c46-4a50-b6a0-00d4c8a9bc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot access or analyze the PDF file \"file_01.pdf\" as it is not provided in the current context.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"question\": \"What is the following PDF about?\",\n",
    "        \"pdf\": documents[0].metadata[\"source\"],\n",
    "        \"instructions\": \"Answer the question with one sentence only. Do not make things up and say so if you cannot answer the question.\",\n",
    "    }\n",
    ")\n",
    "    \n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7e995-7a82-48cb-8096-7ddfc16c329b",
   "metadata": {},
   "source": [
    "Usually, the LLM answers with something like `I cannot determine the content of the PDF without viewing it.` but from time to time it also makes things up (especially when the filename happens to be something like `invoice_01.pdf` it infers/invents some content)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d61c6a-7584-40c0-b6df-e47c37db58d2",
   "metadata": {},
   "source": [
    "Let's be more specific..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15c4c13b-25b6-48df-b67a-c951960998a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total amount of the PDF invoice is **$264.85**.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"question\": \"What is the total amount of the PDF invoice?\",\n",
    "        \"pdf\": documents[0].page_content,\n",
    "        \"instructions\": \"Answer the question and do not make things up. If you cannot answer the question say 'I cannot answer the question'.\",\n",
    "    }\n",
    ")\n",
    "    \n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fb8469b-8f7c-4e5f-8309-551b55ce8658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot answer the question.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"question\": \"What is the total amount of the PDF invoice?\",\n",
    "        \"pdf\": documents[0].metadata[\"source\"],\n",
    "        \"instructions\": \"Answer the question and do not make things up. If you cannot answer the question say 'I cannot answer the question'.\",\n",
    "    }\n",
    ")\n",
    "    \n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b675290-4aaa-4d12-b846-512109a093ed",
   "metadata": {},
   "source": [
    "It becomes obvious that the LLM cannot answer the question because it cannot access the content of the PDF file. How about a system that can decide about tools to use to fulfill individual task in order to iteratively work towards an answer - i.e. let's build an agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d07950-942d-493a-90b5-729afa72e62f",
   "metadata": {},
   "source": [
    "Let's provide the LLM (resp. Agent) with the functionality to read the content of a PDF file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f71880-825e-4f65-b9f4-952bf28b5184",
   "metadata": {},
   "source": [
    "<font color='red'>**TASK: Program a `Tool` that provides the LLM the possibility to read the content of a PDF (see [Tools](https://docs.langchain.com/oss/python/langchain/agents#tools) for additional input).**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57879039-1844-40a3-a83e-8e7a6e3e30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@...\n",
    "def read_pdf_content..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d76db22a-62e9-493c-aacc-b468db3d3e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Reads the content of a PDF file.\\n\\nArgs:\\n    pdf_file_path: The path of the PDF file to read',\n",
       " 'properties': {'pdf_file_path': {'title': 'Pdf File Path', 'type': 'string'}},\n",
       " 'required': ['pdf_file_path'],\n",
       " 'title': 'read_pdf_content',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_pdf_content.args_schema.model_json_schema()\n",
    "#print(read_pdf_content.name)\n",
    "#print(read_pdf_content.description)\n",
    "#print(read_pdf_content.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ef6d1-de6e-49c6-97af-e04665d5cdea",
   "metadata": {},
   "source": [
    "<font color='red'>**TASK: Create an `Agent` that can use your `Tool` to access the content of a PDF in order to be able to answer your question(s) about this PDF (see [Agents](https://docs.langchain.com/oss/python/langchain/agents) for additional input).**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4071dfe-a5e1-4576-9147-b50970c54572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a96c4fbd-7766-48fa-a2f6-84ec13214964",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = prompt | agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4afbba12-cda4-4a7e-b508-dd28c6971f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"What is the total amount of the PDF invoice?\",\n",
    "        \"pdf\": documents[0].metadata[\"source\"],\n",
    "        \"instructions\": \"Answer the question and do not make things up. If you cannot answer the question say 'I cannot answer the question'.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a837b12-9d2c-4c5b-924b-5baddfb23562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total amount of the PDF invoice is $264.85.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e212869d-9c7c-47bc-8279-1d2e4acc9d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5306533f-aa37-48b9-8bdd-fe67650f6a32",
   "metadata": {},
   "source": [
    "Let's try to build an Agent that provides structured output..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b026e448-2865-4be1-a0db-bb86593d76fe",
   "metadata": {},
   "source": [
    "<font color='red'>**TASK: Create an `Agent` that provides structured output about the total amout of an invoice PDF (see [Advanced Concepts](https://docs.langchain.com/oss/python/langchain/agents#advanced-concepts) for additional input).**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba02ea36-0ed2-4555-8100-9a0cfe4d0a54",
   "metadata": {},
   "source": [
    "Unfortunately, I have not been able to get this up and running (probably because I use Ollama and not OpenAI). In case you are successful, please let me know..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e056bbc-60b5-4bd1-a5e7-15d0753595e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f249199-de5c-47bf-9ea8-fdf1f3c40fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Invoice(BaseModel):\n",
    "    \"\"\"An invoice with different properties.\"\"\"\n",
    "    \n",
    "    total_amount: str = Field(description=\"The total amount of the invoice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21c3130a-109a-432a-8890-6047a24051ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "# ToolStrategy, ProviderStrategy does not seem to work (yet?)\n",
    "from langchain.agents.structured_output import ToolStrategy, ProviderStrategy\n",
    "\n",
    "# ToolStrategy, ProviderStrategy does not seem to work (yet?)\n",
    "structured_agent = create_agent(llm, tools=[read_pdf_content], response_format=ToolStrategy(Invoice))\n",
    "#structured_agent = create_agent(llm, tools=[read_pdf_content], response_format=Invoice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "468fafcd-8808-4595-b4c5-df06d9d842c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_agent_chain = prompt | structured_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a52db10d-9710-42ca-98cd-4156389e31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = structured_agent_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"What is the total amount of the PDF invoice?\",\n",
    "        \"pdf\": documents[0].metadata[\"source\"],\n",
    "        \"instructions\": \"Answer the question and do not make things up. If you cannot answer the question say 'I cannot answer the question'.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cda0a6e-b8b0-4f5b-9988-3e6fb32d05ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [SystemMessage(content='You are a helpful assistant that analyzes a PDF. Be concise and accurate.', additional_kwargs={}, response_metadata={}, id='694cc6e8-6e0b-4941-8701-3a458d644539'), HumanMessage(content=\"Please answer the question 'Extract the total amount of the PDF invoice.' about following PDF 'data/pdfs/file_01.pdf'. Adhere to following additional instructions: 'Answer the question and do not make things up. If you cannot answer the question say 'I cannot answer the question'.'\", additional_kwargs={}, response_metadata={}, id='841b81ac-486b-452e-8418-472884814a5a'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1045, 'prompt_tokens': 295, 'total_tokens': 1340, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen3:4b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-390', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--6b551a17-ccee-4389-ae1b-7671b92b7094-0', tool_calls=[{'name': 'read_pdf_content', 'args': {'pdf_file_path': 'data/pdfs/file_01.pdf'}, 'id': 'call_jswopkwt', 'type': 'tool_call'}], usage_metadata={'input_tokens': 295, 'output_tokens': 1045, 'total_tokens': 1340, 'input_token_details': {}, 'output_token_details': {}}), ToolMessage(content='John Smith\\n4490 Oak Drive\\nAlbarry, NY 12210\\nAlbarry 15.11.2025\\nJessie Home\\n4312 Wood Road\\nNew York, NY 10031\\nInvoice\\nDate Description QTY Unit Price Amount\\n14.11.2025 Front and rear brake cables 1 $15.00 $15.00\\n14.11.2025 New set of pedal arms 2 $25.00 $50.00\\n14.11.2025 Labor 3 $60.00 $180.00\\nTax 8.10% $19.85\\nTotal Payment due within 30 Days (15.12.2025) $264.85\\nThank you\\nJohn Smith\\nSeite 1\\n', name='read_pdf_content', id='c7bce7cd-cf08-4b25-b44a-9634721a6a94', tool_call_id='call_jswopkwt'), AIMessage(content='The total amount of the PDF invoice is $264.85.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 200, 'prompt_tokens': 545, 'total_tokens': 745, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen3:4b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-40', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--c508fd37-5df1-43ff-9575-9b2571fc59f6-0', usage_metadata={'input_tokens': 545, 'output_tokens': 200, 'total_tokens': 745, 'input_token_details': {}, 'output_token_details': {}})]}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d49528c3-8ea2-4cde-9b7f-73055d3e2857",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'structured_response'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# this does not work :-(\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstructured_response\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[31mKeyError\u001b[39m: 'structured_response'"
     ]
    }
   ],
   "source": [
    "# this does not work :-(\n",
    "\n",
    "print(result[\"structured_response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2046ad-df9a-41c2-881e-05f54c26691d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf8001a-4bf8-404a-a58b-bec69a567131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
